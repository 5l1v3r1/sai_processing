{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "\n",
    "'''\n",
    "найти дескрипторы\n",
    "и\n",
    "совместить\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "noises = ['None','gauss', 's&p', 'poisson', 'speckle']\n",
    "\n",
    "def noisy(noise_typ,image):\n",
    "    if noise_typ == \"gauss\":\n",
    "        row,col,ch= image.shape\n",
    "        mean = 0\n",
    "        var = 0.1\n",
    "        sigma = var**0.5\n",
    "        gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "        gauss = gauss.reshape(row,col,ch)\n",
    "        noisy = image + gauss\n",
    "        return noisy\n",
    "    elif noise_typ == \"s&p\":\n",
    "        row,col,ch = image.shape\n",
    "        s_vs_p = 0.5\n",
    "        amount = 0.004\n",
    "        out = np.copy(image)\n",
    "        # Salt mode\n",
    "        num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "        coords = [np.random.randint(0, i - 1, int(num_salt))\n",
    "              for i in image.shape]\n",
    "        out[tuple(coords)] = 1\n",
    "\n",
    "        # Pepper mode\n",
    "        num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "        coords = [np.random.randint(0, i - 1, int(num_pepper))\n",
    "              for i in image.shape]\n",
    "        out[tuple(coords)] = 0\n",
    "        return out\n",
    "    elif noise_typ == \"poisson\":\n",
    "        vals = len(np.unique(image))\n",
    "        vals = 2 ** np.ceil(np.log2(vals))\n",
    "        noisy = np.random.poisson(image * vals) / float(vals)\n",
    "        return noisy\n",
    "    elif noise_typ ==\"speckle\":\n",
    "        row,col,ch = image.shape\n",
    "        gauss = np.random.randn(row,col,ch)\n",
    "        gauss = gauss.reshape(row,col,ch)        \n",
    "        noisy = image + image * gauss\n",
    "        return noisy\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matcher BRUTEFORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ecf2db93ed844c8a151ff2fe6aaaed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='noise', options=('None', 'gauss', 's&p', 'poisson', 'speckle'), va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual(noise=noises, rotate=(0, 360), scale=(0.5, 1.5, 1e-2),\n",
    "          minHessian=(1, 50000, 1))\n",
    "def features_1_detect(noise, rotate, scale,\n",
    "                   minHessian):\n",
    "    \n",
    "    \n",
    "    \n",
    "    src = cv.imread('grabCut/bike.jpg')\n",
    "    #src_gray = cv.medianBlur(src_gray, 5)\n",
    "    src = cv.cvtColor(src, cv.COLOR_BGR2RGB)\n",
    "    \n",
    "    src_gray = cv.cvtColor(src, cv.COLOR_RGB2GRAY)\n",
    "    \n",
    "    img = src.copy()\n",
    "    num_rows, num_cols = img.shape[:2]\n",
    "\n",
    "    rotation_matrix = cv.getRotationMatrix2D((num_cols/2, num_rows/2), rotate, scale)\n",
    "    \n",
    "    \n",
    "    img = noisy(noise, img)\n",
    "    img = img.astype('uint8')\n",
    "    \n",
    "    \n",
    "    img = cv.warpAffine(img, rotation_matrix, (num_cols, num_rows))\n",
    "    \n",
    "    img_gray = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "    \n",
    "    #-- Step 1: Detect the keypoints using SURF Detector, compute the descriptors\n",
    "    detector = cv.xfeatures2d_SURF.create(hessianThreshold=minHessian)\n",
    "    \n",
    "    keypoints1, descriptors1 = detector.detectAndCompute(src_gray, None)\n",
    "    keypoints2, descriptors2 = detector.detectAndCompute(img_gray, None)\n",
    "    #-- Step 2: Matching descriptor vectors with a brute force matcher\n",
    "    # Since SURF is a floating-point descriptor NORM_L2 is used\n",
    "    \n",
    "    matcher = cv.DescriptorMatcher_create(cv.DescriptorMatcher_BRUTEFORCE)\n",
    "    matches = matcher.match(descriptors1, descriptors2)\n",
    "    \n",
    "    #-- Draw matches\n",
    "    img_matches = np.empty((max(src.shape[0], img.shape[0]), src.shape[1]+img.shape[1], 3), dtype=np.uint8)\n",
    "    cv.drawMatches(src, keypoints1, img, keypoints2, matches, img_matches)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    titles = ['img_matches']#['Original Image', 'Tpl', 'C Image', 'C Tpl']\n",
    "    images = [img_matches]#[src, tpl, dst_src, dst_tpl]\n",
    "    #fig = plt.gcf()\n",
    "    #fig.set_size_inches(20, 20)\n",
    "    for i in range(len(images)):\n",
    "        #plt.subplot(2, 3, i+1)\n",
    "        plt.figure(figsize = (20,10))\n",
    "        plt.imshow(images[i], aspect='auto')\n",
    "        plt.title(titles[i])\n",
    "        plt.xticks([]),\n",
    "        plt.yticks([])\n",
    "    plt.show()\n",
    "    return (rotate, scale)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matcher_FLANNBASED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373ba68cd0fc4aebb388b12121b7088e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='noise', options=('None', 'gauss', 's&p', 'poisson', 'speckle'), va…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact_manual(noise=noises, rotate=(0, 360), scale=(0.5, 1.5, 1e-2),\n",
    "          minHessian=(1, 50000, 1), ratio_thresh=(0.1, 2.0, 0.1))\n",
    "def features_2_detect(noise, rotate, scale,\n",
    "                   minHessian, ratio_thresh):\n",
    "    \n",
    "    \n",
    "    \n",
    "    src = cv.imread('grabCut/bike.jpg')\n",
    "    #src_gray = cv.medianBlur(src_gray, 5)\n",
    "    src = cv.cvtColor(src, cv.COLOR_BGR2RGB)\n",
    "    \n",
    "    src_gray = cv.cvtColor(src, cv.COLOR_RGB2GRAY)\n",
    "    \n",
    "    img = src.copy()\n",
    "    num_rows, num_cols = img.shape[:2]\n",
    "\n",
    "    rotation_matrix = cv.getRotationMatrix2D((num_cols/2, num_rows/2), rotate, scale)\n",
    "    \n",
    "    \n",
    "    img = noisy(noise, img)\n",
    "    img = img.astype('uint8')\n",
    "    \n",
    "    \n",
    "    img = cv.warpAffine(img, rotation_matrix, (num_cols, num_rows))\n",
    "    \n",
    "    img_gray = cv.cvtColor(img, cv.COLOR_RGB2GRAY)\n",
    "    \n",
    "    detector = cv.xfeatures2d_SURF.create(hessianThreshold=minHessian)\n",
    "    \n",
    "    keypoints1, descriptors1 = detector.detectAndCompute(src_gray, None)\n",
    "    keypoints2, descriptors2 = detector.detectAndCompute(img_gray, None)\n",
    "    \n",
    "    #-- Step 2: Matching descriptor vectors with a FLANN based matcher\n",
    "    # Since SURF is a floating-point descriptor NORM_L2 is used\n",
    "    matcher = cv.DescriptorMatcher_create(cv.DescriptorMatcher_FLANNBASED)\n",
    "    knn_matches = matcher.knnMatch(descriptors1, descriptors2, 2)\n",
    "    #-- Filter matches using the Lowe's ratio test\n",
    "    \n",
    "    good_matches = []\n",
    "    for m,n in knn_matches:\n",
    "        if m.distance < ratio_thresh * n.distance:\n",
    "            good_matches.append(m)\n",
    "    #-- Draw matches\n",
    "    img_matches = np.empty((max(src.shape[0], img.shape[0]), src.shape[1]+img.shape[1], 3), dtype=np.uint8)\n",
    "    cv.drawMatches(src, keypoints1, img, keypoints2, good_matches, img_matches, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    titles = ['img_matches']#['Original Image', 'Tpl', 'C Image', 'C Tpl']\n",
    "    images = [img_matches]#[src, tpl, dst_src, dst_tpl]\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(20, 20)\n",
    "    for i in range(len(images)):\n",
    "        #plt.subplot(2, 3, i+1)\n",
    "        plt.figure(figsize = (20,10))\n",
    "        plt.imshow(images[i], aspect='auto')\n",
    "        plt.title(titles[i])\n",
    "        plt.xticks([]),\n",
    "        plt.yticks([])\n",
    "    plt.show()\n",
    "    return (rotate, scale)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VPython",
   "language": "python",
   "name": "vpython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
